{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53bc8bd1-0861-4341-be91-db437d593c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import pyedflib\n",
    "import json\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c065c884-9eae-42dc-9e51-5a33093a355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilya\\Documents\\GitHub\\EEG_feedback\\EEG_preprocessing\\data\n",
      "Extracting EDF parameters from C:\\Users\\Ilya\\Documents\\GitHub\\EEG_feedback\\EEG_preprocessing\\data\\eeg-03-05-23_16-35 (9, noisy).edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 205624  =      0.000 ...  1644.992 secs...\n",
      "Used Annotations descriptions: ['end task', 'right_answer', 'start task', 'wrong_answer']\n",
      "{'end task': 1, 'right_answer': 2, 'start task': 3, 'wrong_answer': 4}\n",
      "[2, 4]\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 40 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth lowpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoff at 40.00 Hz: -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 2 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth highpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoff at 2.00 Hz: -6.02 dB\n",
      "\n",
      "Extracting EDF parameters from C:\\Users\\Ilya\\Documents\\GitHub\\EEG_feedback\\EEG_preprocessing\\data\\eeg-03-05-23_19-03 (испорчено).edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 44999  =      0.000 ...   359.992 secs...\n",
      "Used Annotations descriptions: ['end task', 'start task', 'wrong_answer']\n",
      "{'end task': 1, 'start task': 2, 'wrong_answer': 3}\n",
      "[3]\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 40 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth lowpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoff at 40.00 Hz: -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 2 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth highpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoff at 2.00 Hz: -6.02 dB\n",
      "\n",
      "Extracting EDF parameters from C:\\Users\\Ilya\\Documents\\GitHub\\EEG_feedback\\EEG_preprocessing\\data\\eeg-12-05-23_13-07 (испорчено).edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3999  =      0.000 ...    31.992 secs...\n",
      "Used Annotations descriptions: ['end task', 'start task', 'wrong_answer']\n",
      "{'end task': 1, 'start task': 2, 'wrong_answer': 3}\n",
      "[3]\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 40 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth lowpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoff at 40.00 Hz: -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 2 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth highpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoff at 2.00 Hz: -6.02 dB\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 8 and the array at index 1 has size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m ans \u001b[38;5;241m=\u001b[39m raw_data[:,(arr_events[i,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mj):(arr_events[i,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m250\u001b[39m\u001b[38;5;241m+\u001b[39mj)]\n\u001b[0;32m     61\u001b[0m ans \u001b[38;5;241m=\u001b[39m ans\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,ans\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],ans\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 62\u001b[0m ans_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr_events[i,\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m event_names[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     64\u001b[0m     marks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 8 and the array at index 1 has size 6"
     ]
    }
   ],
   "source": [
    "data = np.zeros((1,8,250))\n",
    "marks = []\n",
    "\n",
    "dir_str = os.path.dirname(os.path.abspath(\"__file__\"))+(\"\\data\")\n",
    "data_dir = Path(dir_str)\n",
    "print(data_dir)\n",
    "\n",
    "for file in data_dir.iterdir():\n",
    "    if file.suffix == \".edf\":\n",
    "        #exclude spoiled files\n",
    "        if \"spoiled\" in file.__str__():\n",
    "            continue\n",
    "\n",
    "        #exclude noisy files\n",
    "        #if \"noisy\" in file.__str__():\n",
    "        #    continue\n",
    "        \n",
    "        loaded_data = mne.io.read_raw_edf(file.__str__())\n",
    "        loaded_data.load_data()\n",
    "        \n",
    "        events = mne.events_from_annotations(loaded_data)\n",
    "        arr_events = events[0]\n",
    "        dict = events[1]\n",
    "        event_names = []\n",
    "        print(dict)\n",
    "\n",
    "        #forming event names array\n",
    "        if \"right answer\" in dict:\n",
    "            event_names.append(dict[\"right answer\"])\n",
    "        if \"right_answer\" in dict:\n",
    "            event_names.append(dict[\"right_answer\"])\n",
    "        if \"fake wrong answer\" in dict:\n",
    "            event_names.append(dict[\"fake wrong answer\"])\n",
    "        if \"wrong answer, shown\" in dict:\n",
    "            event_names.append(dict[\"wrong answer, shown\"])\n",
    "        if \"wrong answer\" in dict:\n",
    "            event_names.append(dict[\"wrong answer\"])\n",
    "        if \"wrong_answer\" in dict:\n",
    "            event_names.append(dict[\"wrong_answer\"])\n",
    "        print(event_names)\n",
    "\n",
    "        #add filters\n",
    "        filtered_data = loaded_data.copy().filter(l_freq=None, h_freq=40., fir_design='firwin', method='iir', iir_params=None)\n",
    "        filtered_data = filtered_data.copy().filter(l_freq=2.,h_freq=None, fir_design='firwin', method='iir', iir_params=None)\n",
    "        raw_data = filtered_data.get_data()\n",
    "\n",
    "        #forming answers event array\n",
    "        num = 0\n",
    "        for i in range(arr_events.shape[0]):\n",
    "            if arr_events[i,2] in event_names:\n",
    "                num = i\n",
    "                if (arr_events[i,0] == arr_events[i+1,0]):\n",
    "                    break\n",
    "\n",
    "        #separate asnwers (125 dots, 1 sec)\n",
    "        ans_data = np.zeros((1,8,250))\n",
    "        for i in range(num):\n",
    "            if arr_events[i,2] in event_names:\n",
    "                for j in range(20):\n",
    "                    ans = raw_data[:,(arr_events[i,0]+j):(arr_events[i,0]+250+j)]\n",
    "                    ans = ans.reshape(1,ans.shape[0],ans.shape[1])\n",
    "                    ans_data = np.concatenate((ans_data, ans), axis=0)\n",
    "                    if arr_events[i,2] == event_names[0]:\n",
    "                        marks.append(1)\n",
    "                    else:\n",
    "                        marks.append(0)\n",
    "        ans_data = ans_data[1:,:,:]\n",
    "        data = np.concatenate((data, ans_data), axis=0)\n",
    "        \n",
    "data = data[1:,:,:]\n",
    "#clear_output()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890b3fbe-ab7e-417d-b0db-59a29942dc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 2, 2)\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[[[ 1, 0], [0,  2]],  [[ 3, 0], [0,  4]],  [[17, 0], [0, 18]],  [[19, 0], [0, 20]],  [[33, 0], [0, 34]]],\n",
    "              [[[ 5, 0], [0,  6]],  [[ 7, 0], [0,  8]],  [[21, 0], [0, 22]],  [[23, 0], [0, 24]],  [[35, 0], [0, 36]]],\n",
    "              [[[ 9, 0], [0, 10]],  [[11, 0], [0, 12]],  [[25, 0], [0, 26]],  [[27, 0], [0, 28]],  [[37, 0], [0, 38]]],\n",
    "              [[[13, 0], [0, 14]],  [[15, 0], [0, 16]],  [[29, 0], [0, 30]],  [[31, 0], [0, 32]],  [[39, 0], [0, 40]]]])\n",
    "print(A.shape)\n",
    "\n",
    "B = np.array([])\n",
    "for i in range(A.shape[0]):\n",
    "    if i%2 != 0:\n",
    "        print(i)\n",
    "        continue\n",
    "    for j in range(A.shape[1]):\n",
    "        for m in range(A.shape[2]):\n",
    "            B = np.append(B, A[i][j][m])\n",
    "            B = np.append(B, A[i+1][j][m])\n",
    "B = B.reshape(2,5,2,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26b040da-ad16-42ce-b1dd-cf304fcd19dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#stft experiments\n",
    "stft = librosa.core.stft(data, n_fft=62)\n",
    "spec = np.abs(stft)\n",
    "\n",
    "#B = np.array([])\n",
    "#for i in range(spec.shape[0]):\n",
    "#    if i%2 != 0:\n",
    "#        continue\n",
    "#    for j in range(spec.shape[1]):\n",
    "#        for m in range(spec.shape[2]):\n",
    "#            B = np.append(B, spec[i][j][m])\n",
    "#            B = np.append(B, spec[i+1][j][m])\n",
    "\n",
    "#spec = B.reshape(int(spec.shape[0]/2),spec.shape[1],spec.shape[2],spec.shape[3]*2)\n",
    "librosa.display.specshow(spec[0][0], sr=125.00)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "16b4067c-6730-4e46-b5da-f9e44a852bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8, 32, 17)\n"
     ]
    }
   ],
   "source": [
    "print(spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "549f9c34-dae5-4b1a-bb2a-cc77b45c3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1c7f7095-e3ca-407e-95a8-6e5e4d831e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spec.swapaxes(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b52ebd0b-e66f-4a5b-a42f-2e8776a7db25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_75\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_75/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_75/Conv2D/ReadVariableOp)' with input shapes: [?,6,2,32], [3,3,32,64].\n\nCall arguments received by layer \"conv2d_75\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 6, 2, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\EEG_feedback\\EEG_testing\\env\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\EEG_feedback\\EEG_testing\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\EEG_feedback\\EEG_testing\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1751\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1748\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1749\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1750\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1751\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_75\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_75/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_75/Conv2D/ReadVariableOp)' with input shapes: [?,6,2,32], [3,3,32,64].\n\nCall arguments received by layer \"conv2d_75\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 6, 2, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, activation='relu', input_shape=(spec[0].shape)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4dabaa3f-e370-42b9-ac4c-18bb05a21953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 15, 30, 32)        2336      \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPooli  (None, 7, 15, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 5, 13, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPooli  (None, 2, 6, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               98560     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110401 (431.25 KB)\n",
      "Trainable params: 110401 (431.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(spec[0].shape)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "195af568-170b-4eea-b0a6-48522223f0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_104 (Conv2D)         (None, 16, 31, 16)        528       \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPooli  (None, 8, 15, 16)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 7, 14, 16)         1040      \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPooli  (None, 3, 7, 16)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 2, 6, 16)          1040      \n",
      "                                                                 \n",
      " batch_normalization_51 (Ba  (None, 2, 6, 16)          64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 1, 5, 32)          2080      \n",
      "                                                                 \n",
      " batch_normalization_52 (Ba  (None, 1, 5, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 512)               82432     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 218897 (855.07 KB)\n",
      "Trainable params: 218801 (854.69 KB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 2, activation='relu', input_shape=(spec[0].shape)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(16, 2, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(16, 2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, 2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9fc032b-70da-4fb6-8c47-6669ef9bf067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 6, 31, 16)         4624      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 6, 31, 16)         64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 4, 29, 16)         2320      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 4, 29, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1856)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               237696    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244897 (956.63 KB)\n",
      "Trainable params: 244833 (956.38 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(spec[0].shape)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7edbb822-b115-4236-9c1e-34d040f4d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 17, 32, 8) (190, 17, 32, 8) (570,) (190,)\n"
     ]
    }
   ],
   "source": [
    "#forming data array\n",
    "X = spec.copy()\n",
    "X.shape\n",
    "\n",
    "#forming true answers array\n",
    "Y = np.array(marks)\n",
    "Y.shape\n",
    "\n",
    "x_t = X[240:,:,:,:]\n",
    "x_test = X[:240,:,:,:]\n",
    "y_t = Y[240:]\n",
    "y_test = Y[:240]\n",
    "        \n",
    "x_train, x_val, y_train, y_val = train_test_split(x_t, y_t, test_size=0.25, random_state=20)\n",
    "\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "train = (x_train.copy(), y_train.copy())\n",
    "val = (x_val.copy(), y_val.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce366baa-28ea-4fb0-99e7-72ff00bfd989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "18/18 [==============================] - 2s 25ms/step - loss: 0.6640 - accuracy: 0.5877 - val_loss: 0.6823 - val_accuracy: 0.5737\n",
      "Epoch 2/35\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5889 - accuracy: 0.6807 - val_loss: 0.6824 - val_accuracy: 0.5737\n",
      "Epoch 3/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4781 - accuracy: 0.7789 - val_loss: 0.7410 - val_accuracy: 0.5737\n",
      "Epoch 4/35\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.3232 - accuracy: 0.8719 - val_loss: 0.8324 - val_accuracy: 0.5737\n",
      "Epoch 5/35\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1407 - accuracy: 0.9702 - val_loss: 1.3026 - val_accuracy: 0.5737\n",
      "Epoch 6/35\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0339 - accuracy: 0.9982 - val_loss: 2.2377 - val_accuracy: 0.5737\n",
      "Epoch 7/35\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.3853 - val_accuracy: 0.5737\n",
      "Epoch 8/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.5003 - val_accuracy: 0.5737\n",
      "Epoch 9/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4833 - val_accuracy: 0.5737\n",
      "Epoch 10/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6970 - val_accuracy: 0.5737\n",
      "Epoch 11/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7802 - val_accuracy: 0.5737\n",
      "Epoch 12/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 6.6442e-04 - accuracy: 1.0000 - val_loss: 2.9007 - val_accuracy: 0.5737\n",
      "Epoch 13/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 5.8547e-04 - accuracy: 1.0000 - val_loss: 2.9412 - val_accuracy: 0.5737\n",
      "Epoch 14/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 3.3651e-04 - accuracy: 1.0000 - val_loss: 2.9893 - val_accuracy: 0.5737\n",
      "Epoch 15/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 3.0765e-04 - accuracy: 1.0000 - val_loss: 3.0226 - val_accuracy: 0.5737\n",
      "Epoch 16/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 2.3389e-04 - accuracy: 1.0000 - val_loss: 3.0406 - val_accuracy: 0.5737\n",
      "Epoch 17/35\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2.5592e-04 - accuracy: 1.0000 - val_loss: 3.0559 - val_accuracy: 0.5737\n",
      "Epoch 18/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 2.3409e-04 - accuracy: 1.0000 - val_loss: 3.0511 - val_accuracy: 0.5737\n",
      "Epoch 19/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.7521e-04 - accuracy: 1.0000 - val_loss: 3.0241 - val_accuracy: 0.5737\n",
      "Epoch 20/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.7916e-04 - accuracy: 1.0000 - val_loss: 3.0062 - val_accuracy: 0.5737\n",
      "Epoch 21/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.7895e-04 - accuracy: 1.0000 - val_loss: 2.9748 - val_accuracy: 0.5737\n",
      "Epoch 22/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.5906e-04 - accuracy: 1.0000 - val_loss: 2.9399 - val_accuracy: 0.5737\n",
      "Epoch 23/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.7082e-04 - accuracy: 1.0000 - val_loss: 2.8709 - val_accuracy: 0.5737\n",
      "Epoch 24/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.1931e-04 - accuracy: 1.0000 - val_loss: 2.7695 - val_accuracy: 0.5737\n",
      "Epoch 25/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 9.1687e-05 - accuracy: 1.0000 - val_loss: 2.6604 - val_accuracy: 0.5789\n",
      "Epoch 26/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.1141e-04 - accuracy: 1.0000 - val_loss: 2.5510 - val_accuracy: 0.6211\n",
      "Epoch 27/35\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1.0877e-04 - accuracy: 1.0000 - val_loss: 2.4829 - val_accuracy: 0.6316\n",
      "Epoch 28/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 8.1305e-05 - accuracy: 1.0000 - val_loss: 2.3562 - val_accuracy: 0.6368\n",
      "Epoch 29/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 6.5659e-05 - accuracy: 1.0000 - val_loss: 2.1798 - val_accuracy: 0.6368\n",
      "Epoch 30/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 7.6934e-05 - accuracy: 1.0000 - val_loss: 1.9180 - val_accuracy: 0.6368\n",
      "Epoch 31/35\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 7.3779e-05 - accuracy: 1.0000 - val_loss: 1.5896 - val_accuracy: 0.6368\n",
      "Epoch 32/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 6.1591e-05 - accuracy: 1.0000 - val_loss: 1.3431 - val_accuracy: 0.6421\n",
      "Epoch 33/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 5.1473e-05 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.6579\n",
      "Epoch 34/35\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 5.3107e-05 - accuracy: 1.0000 - val_loss: 0.7712 - val_accuracy: 0.7053\n",
      "Epoch 35/35\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 5.6260e-05 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.7421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b7035eb7f0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train.copy(), y=y_train.copy(), epochs=35, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "726dbab9-1929-4578-8515-9429f5924b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "true:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pred:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.94      0.56       100\n",
      "           1       0.00      0.00      0.00       140\n",
      "\n",
      "    accuracy                           0.39       240\n",
      "   macro avg       0.20      0.47      0.28       240\n",
      "weighted avg       0.17      0.39      0.23       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pre = model.predict(x_test)\n",
    "y_res = np.where(y_pre > 0.5, 1, 0)\n",
    "print(\"true: \", y_test.copy())\n",
    "print(\"pred: \", y_res.reshape(y_test.shape))\n",
    "print(\"\\n\", classification_report(y_test.copy(), y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80060138-c666-4c65-ace7-6acaed43de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetB6\n",
    "\n",
    "t_spec = spec.swapaxes(1,3)\n",
    "\n",
    "eff_model = EfficientNetB6(include_top=True,\n",
    "                           weights=None,\n",
    "                           input_shape=(t_spec[0].shape),\n",
    "                           pooling=None,\n",
    "                           classes=1,\n",
    "                           classifier_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9259a1cd-7a22-402e-bb64-672f7c6fdb62",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eff_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43meff_model\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinaryCrossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#eff_model.summary()\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eff_model' is not defined"
     ]
    }
   ],
   "source": [
    "eff_model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "#eff_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4395efc-a705-4b12-b04f-1e7124bf9cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 32, 33, 8)\n",
      "(250, 32, 33, 8)\n",
      "(250,)\n",
      "(150, 32, 33, 8) (50, 32, 33, 8) (150,) (50,)\n"
     ]
    }
   ],
   "source": [
    "print(t_spec.shape)\n",
    "\n",
    "#forming data array\n",
    "X = t_spec.copy()\n",
    "print(X.shape)\n",
    "\n",
    "#forming true answers array\n",
    "M = np.array(marks)\n",
    "Y = np.array([])\n",
    "for i in range(M.shape[0]):\n",
    "    if i%2 != 0:\n",
    "        continue\n",
    "    Y = np.append(Y, M[i])\n",
    "print(Y.shape)\n",
    "\n",
    "x_t = X[50:,:,:,:]\n",
    "x_test = X[:50,:,:,:]\n",
    "y_t = Y[50:]\n",
    "y_test = Y[:50]\n",
    "        \n",
    "x_train, x_val, y_train, y_val = train_test_split(x_t, y_t, test_size=0.25, random_state=0)\n",
    "\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "train = (x_train.copy(), y_train.copy())\n",
    "val = (x_val.copy(), y_val.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3fb443ff-34f7-43c9-b914-68b13e17231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 80s 4s/step - loss: 13.4141 - accuracy: 0.6000 - val_loss: 0.8424 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 15.6147 - accuracy: 0.4267 - val_loss: 0.9065 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 10.9123 - accuracy: 0.5400 - val_loss: 1.3594 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 6.9754 - accuracy: 0.4867 - val_loss: 1.4110 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 8.7571 - accuracy: 0.5533 - val_loss: 1.1767 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 6.8829 - accuracy: 0.5667 - val_loss: 0.9593 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 4.7076 - accuracy: 0.5267 - val_loss: 3.4925 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 8.2048 - accuracy: 0.5133 - val_loss: 2.3610 - val_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 4.2318 - accuracy: 0.5667 - val_loss: 0.7613 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 1.5011 - accuracy: 0.5933 - val_loss: 0.7221 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.3509 - accuracy: 0.5200 - val_loss: 0.6761 - val_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 4.0005 - accuracy: 0.5067 - val_loss: 1.0328 - val_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 6.1193 - accuracy: 0.5667 - val_loss: 2.0898 - val_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 1.5877 - accuracy: 0.5733 - val_loss: 1.1328 - val_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 2.7625 - accuracy: 0.5667 - val_loss: 0.6817 - val_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 12s 3s/step - loss: 3.4758 - accuracy: 0.4200 - val_loss: 1.3854 - val_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.9389 - accuracy: 0.5733 - val_loss: 2.0079 - val_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 4.8865 - accuracy: 0.4667 - val_loss: 0.7337 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.4466 - accuracy: 0.5333 - val_loss: 0.9651 - val_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.4313 - accuracy: 0.5067 - val_loss: 1.2780 - val_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.9004 - accuracy: 0.5467 - val_loss: 1.7496 - val_accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 4.7894 - accuracy: 0.5667 - val_loss: 0.8628 - val_accuracy: 0.6000\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.9144 - accuracy: 0.4800 - val_loss: 0.6748 - val_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.6885 - accuracy: 0.5000 - val_loss: 0.9439 - val_accuracy: 0.6000\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.3138 - accuracy: 0.5733 - val_loss: 1.1813 - val_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.4514 - accuracy: 0.5467 - val_loss: 0.9015 - val_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.4212 - accuracy: 0.5267 - val_loss: 0.8394 - val_accuracy: 0.6000\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.9061 - accuracy: 0.5067 - val_loss: 0.7842 - val_accuracy: 0.6000\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.1899 - accuracy: 0.5400 - val_loss: 0.7254 - val_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.2086 - accuracy: 0.5400 - val_loss: 0.8386 - val_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.0404 - accuracy: 0.5400 - val_loss: 0.6736 - val_accuracy: 0.6000\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.5659 - accuracy: 0.4733 - val_loss: 0.6755 - val_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.1798 - accuracy: 0.5133 - val_loss: 0.7006 - val_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.4891 - accuracy: 0.5133 - val_loss: 0.6732 - val_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.3472 - accuracy: 0.5067 - val_loss: 0.6737 - val_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.5277 - accuracy: 0.5133 - val_loss: 0.6852 - val_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.8814 - accuracy: 0.5400 - val_loss: 0.6783 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 4.0195 - accuracy: 0.4867 - val_loss: 0.6772 - val_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.1833 - accuracy: 0.4933 - val_loss: 0.8359 - val_accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0711 - accuracy: 0.5800 - val_loss: 1.0238 - val_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.3390 - accuracy: 0.5467 - val_loss: 0.8712 - val_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.9014 - accuracy: 0.5200 - val_loss: 0.7620 - val_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.5047 - accuracy: 0.4733 - val_loss: 0.6744 - val_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.8597 - accuracy: 0.5533 - val_loss: 0.8540 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.6503 - accuracy: 0.5200 - val_loss: 0.6745 - val_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.3173 - accuracy: 0.4600 - val_loss: 0.7680 - val_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.6618 - accuracy: 0.5000 - val_loss: 0.8348 - val_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.8929 - accuracy: 0.5600 - val_loss: 0.9843 - val_accuracy: 0.6000\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.8478 - accuracy: 0.5800 - val_loss: 0.7948 - val_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.8058 - accuracy: 0.5200 - val_loss: 0.9019 - val_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 4.1838 - accuracy: 0.4467 - val_loss: 0.7356 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.3825 - accuracy: 0.5333 - val_loss: 0.6810 - val_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 4.4947 - accuracy: 0.4600 - val_loss: 0.7125 - val_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.4974 - accuracy: 0.4800 - val_loss: 0.8556 - val_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.8291 - accuracy: 0.5000 - val_loss: 1.0583 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.4425 - accuracy: 0.5467 - val_loss: 0.7343 - val_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.2032 - accuracy: 0.4733 - val_loss: 0.9041 - val_accuracy: 0.4000\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.9208 - accuracy: 0.4667 - val_loss: 0.8063 - val_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.9554 - accuracy: 0.5867 - val_loss: 0.7420 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.8048 - accuracy: 0.6200 - val_loss: 0.7949 - val_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0791 - accuracy: 0.5733 - val_loss: 0.6825 - val_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.6462 - accuracy: 0.5933 - val_loss: 0.6744 - val_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0050 - accuracy: 0.5533 - val_loss: 0.7494 - val_accuracy: 0.4000\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.4410 - accuracy: 0.5400 - val_loss: 0.6784 - val_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.2982 - accuracy: 0.4800 - val_loss: 0.7167 - val_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.4098 - accuracy: 0.5200 - val_loss: 0.7998 - val_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.1962 - accuracy: 0.6000 - val_loss: 1.1504 - val_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.7707 - accuracy: 0.5200 - val_loss: 0.6780 - val_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.8421 - accuracy: 0.4800 - val_loss: 1.1167 - val_accuracy: 0.4000\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.4000 - accuracy: 0.5133 - val_loss: 0.7296 - val_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.3403 - accuracy: 0.5800 - val_loss: 1.3770 - val_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.3681 - accuracy: 0.5467 - val_loss: 1.1474 - val_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.5704 - accuracy: 0.5267 - val_loss: 0.7933 - val_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.6992 - accuracy: 0.5600 - val_loss: 0.7624 - val_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.1064 - accuracy: 0.5000 - val_loss: 0.7098 - val_accuracy: 0.4000\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.1429 - accuracy: 0.5933 - val_loss: 0.9081 - val_accuracy: 0.6000\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.5791 - accuracy: 0.4667 - val_loss: 0.6734 - val_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.5550 - accuracy: 0.5200 - val_loss: 0.7601 - val_accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.4410 - accuracy: 0.4667 - val_loss: 0.6884 - val_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.3323 - accuracy: 0.5600 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.8402 - accuracy: 0.5533 - val_loss: 0.7125 - val_accuracy: 0.6000\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.6108 - accuracy: 0.5733 - val_loss: 0.9750 - val_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.3608 - accuracy: 0.6200 - val_loss: 0.9508 - val_accuracy: 0.6000\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.5860 - accuracy: 0.5800 - val_loss: 0.8950 - val_accuracy: 0.6000\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.0397 - accuracy: 0.5133 - val_loss: 0.6784 - val_accuracy: 0.6000\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.3703 - accuracy: 0.4400 - val_loss: 1.0297 - val_accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.8116 - accuracy: 0.4933 - val_loss: 0.6915 - val_accuracy: 0.6000\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 4.4537 - accuracy: 0.5067 - val_loss: 1.1573 - val_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.3334 - accuracy: 0.5467 - val_loss: 0.6885 - val_accuracy: 0.6000\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5231 - accuracy: 0.4600 - val_loss: 1.1291 - val_accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.2174 - accuracy: 0.4600 - val_loss: 0.7683 - val_accuracy: 0.4000\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.5668 - accuracy: 0.5467 - val_loss: 0.7420 - val_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.0095 - accuracy: 0.5667 - val_loss: 0.8287 - val_accuracy: 0.6000\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.8315 - accuracy: 0.5600 - val_loss: 0.7769 - val_accuracy: 0.6000\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.1769 - accuracy: 0.5467 - val_loss: 0.7569 - val_accuracy: 0.6000\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.9201 - accuracy: 0.5400 - val_loss: 0.7762 - val_accuracy: 0.6000\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.1975 - accuracy: 0.5000 - val_loss: 0.6823 - val_accuracy: 0.6000\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.7554 - accuracy: 0.5867 - val_loss: 0.7184 - val_accuracy: 0.6000\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.1100 - accuracy: 0.4933 - val_loss: 0.6898 - val_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.5003 - accuracy: 0.5733 - val_loss: 0.6753 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1df26f1a340>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_model.fit(x=x_train.copy(), y=y_train.copy(), epochs=100, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d1c87-9811-4cd4-9910-e78c278624d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
